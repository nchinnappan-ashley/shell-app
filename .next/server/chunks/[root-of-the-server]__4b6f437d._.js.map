{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 55, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/NChinnappan/SourceAI/UI/shell-app/src/lib/rag/store.ts"],"sourcesContent":["export type StoredChunk = { id: string; url: string; title?: string; text: string };\n\n// Sparse BM25/TF-IDF store (no external dependencies)\n\ntype SparseDoc = {\n  id: string;\n  url: string;\n  title?: string;\n  text: string;\n  length: number; // token count\n};\n\ntype Store = {\n  docs: Map<string, SparseDoc>;\n  // inverted index: term -> map(docId -> term frequency in doc)\n  inv: Map<string, Map<string, number>>;\n  // document frequencies: term -> number of docs containing term\n  df: Map<string, number>;\n  // total docs and average doc length\n  N: number;\n  avgdl: number;\n};\n\n// Global in-memory store (persists for server process lifetime)\nconst g = globalThis as unknown as { __RAG_SPARSE_STORE?: Store };\nif (!g.__RAG_SPARSE_STORE) {\n  g.__RAG_SPARSE_STORE = { docs: new Map(), inv: new Map(), df: new Map(), N: 0, avgdl: 0 } as Store;\n}\nconst store: Store = g.__RAG_SPARSE_STORE as Store;\n\nfunction normalize(s: string) {\n  return s.toLowerCase().replace(/[^a-z0-9 ]/g, ' ').replace(/\\s+/g, ' ').trim();\n}\nfunction tokenize(text: string): string[] {\n  return normalize(text).split(' ').filter(Boolean);\n}\n\nexport function addSparseDocuments(items: StoredChunk[]) {\n  for (const it of items) {\n    const tokens = tokenize(it.text);\n    const tf = new Map<string, number>();\n    const seen = new Set<string>();\n    for (const t of tokens) {\n      tf.set(t, (tf.get(t) || 0) + 1);\n      if (!seen.has(t)) {\n        seen.add(t);\n        store.df.set(t, (store.df.get(t) || 0) + 1);\n      }\n    }\n    // write to inverted index\n    tf.forEach((freq, term) => {\n      let postings = store.inv.get(term);\n      if (!postings) { postings = new Map(); store.inv.set(term, postings); }\n      postings.set(it.id, freq);\n    });\n    // add doc\n    store.docs.set(it.id, { id: it.id, url: it.url, title: it.title, text: it.text, length: tokens.length });\n  }\n  // update corpus stats\n  store.N = store.docs.size;\n  let totalLen = 0;\n  store.docs.forEach(d => totalLen += d.length);\n  store.avgdl = store.N ? totalLen / store.N : 0;\n}\n\nexport function resetStore() {\n  store.docs.clear();\n  store.inv.clear();\n  store.df.clear();\n  store.N = 0;\n  store.avgdl = 0;\n}\n\nexport function size() {\n  return { count: store.docs.size, avgdl: store.avgdl };\n}\n\nexport function listDocs(limit = 50) {\n  const arr: { id: string; url: string; title?: string; length: number }[] = [];\n  store.docs.forEach((d) => arr.push({ id: d.id, url: d.url, title: d.title, length: d.length }));\n  return arr.slice(0, Math.max(0, limit));\n}\n\n// BM25 scoring\nexport function searchSparse(query: string, k = 5, k1 = 1.5, b = 0.75) {\n  const qTokens = tokenize(query);\n  const qTerms = Array.from(new Set(qTokens));\n  const scores = new Map<string, number>();\n  for (const term of qTerms) {\n    const df = store.df.get(term) || 0;\n    if (df === 0 || store.N === 0) continue;\n    const idf = Math.log(1 + (store.N - df + 0.5) / (df + 0.5));\n    const postings = store.inv.get(term)!;\n    postings?.forEach((tf, docId) => {\n      const d = store.docs.get(docId)!;\n      const denom = tf + k1 * (1 - b + b * (d.length / (store.avgdl || 1)));\n      const scoreAdd = idf * ((tf * (k1 + 1)) / (denom || 1));\n      scores.set(docId, (scores.get(docId) || 0) + scoreAdd);\n    });\n  }\n  const ranked = Array.from(scores.entries())\n    .sort((a, b2) => b2[1] - a[1])\n    .slice(0, k)\n    .map(([docId, s]) => {\n      const d = store.docs.get(docId)!;\n      return { id: d.id, url: d.url, title: d.title, text: d.text, score: s };\n    });\n  return ranked;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAuBA,gEAAgE;AAChE,MAAM,IAAI;AACV,IAAI,CAAC,EAAE,kBAAkB,EAAE;IACzB,EAAE,kBAAkB,GAAG;QAAE,MAAM,IAAI;QAAO,KAAK,IAAI;QAAO,IAAI,IAAI;QAAO,GAAG;QAAG,OAAO;IAAE;AAC1F;AACA,MAAM,QAAe,EAAE,kBAAkB;AAEzC,SAAS,UAAU,CAAS;IAC1B,OAAO,EAAE,WAAW,GAAG,OAAO,CAAC,eAAe,KAAK,OAAO,CAAC,QAAQ,KAAK,IAAI;AAC9E;AACA,SAAS,SAAS,IAAY;IAC5B,OAAO,UAAU,MAAM,KAAK,CAAC,KAAK,MAAM,CAAC;AAC3C;AAEO,SAAS,mBAAmB,KAAoB;IACrD,KAAK,MAAM,MAAM,MAAO;QACtB,MAAM,SAAS,SAAS,GAAG,IAAI;QAC/B,MAAM,KAAK,IAAI;QACf,MAAM,OAAO,IAAI;QACjB,KAAK,MAAM,KAAK,OAAQ;YACtB,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI;YAC7B,IAAI,CAAC,KAAK,GAAG,CAAC,IAAI;gBAChB,KAAK,GAAG,CAAC;gBACT,MAAM,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI;YAC3C;QACF;QACA,0BAA0B;QAC1B,GAAG,OAAO,CAAC,CAAC,MAAM;YAChB,IAAI,WAAW,MAAM,GAAG,CAAC,GAAG,CAAC;YAC7B,IAAI,CAAC,UAAU;gBAAE,WAAW,IAAI;gBAAO,MAAM,GAAG,CAAC,GAAG,CAAC,MAAM;YAAW;YACtE,SAAS,GAAG,CAAC,GAAG,EAAE,EAAE;QACtB;QACA,UAAU;QACV,MAAM,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE;YAAE,IAAI,GAAG,EAAE;YAAE,KAAK,GAAG,GAAG;YAAE,OAAO,GAAG,KAAK;YAAE,MAAM,GAAG,IAAI;YAAE,QAAQ,OAAO,MAAM;QAAC;IACxG;IACA,sBAAsB;IACtB,MAAM,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI;IACzB,IAAI,WAAW;IACf,MAAM,IAAI,CAAC,OAAO,CAAC,CAAA,IAAK,YAAY,EAAE,MAAM;IAC5C,MAAM,KAAK,GAAG,MAAM,CAAC,GAAG,WAAW,MAAM,CAAC,GAAG;AAC/C;AAEO,SAAS;IACd,MAAM,IAAI,CAAC,KAAK;IAChB,MAAM,GAAG,CAAC,KAAK;IACf,MAAM,EAAE,CAAC,KAAK;IACd,MAAM,CAAC,GAAG;IACV,MAAM,KAAK,GAAG;AAChB;AAEO,SAAS;IACd,OAAO;QAAE,OAAO,MAAM,IAAI,CAAC,IAAI;QAAE,OAAO,MAAM,KAAK;IAAC;AACtD;AAEO,SAAS,SAAS,QAAQ,EAAE;IACjC,MAAM,MAAqE,EAAE;IAC7E,MAAM,IAAI,CAAC,OAAO,CAAC,CAAC,IAAM,IAAI,IAAI,CAAC;YAAE,IAAI,EAAE,EAAE;YAAE,KAAK,EAAE,GAAG;YAAE,OAAO,EAAE,KAAK;YAAE,QAAQ,EAAE,MAAM;QAAC;IAC5F,OAAO,IAAI,KAAK,CAAC,GAAG,KAAK,GAAG,CAAC,GAAG;AAClC;AAGO,SAAS,aAAa,KAAa,EAAE,IAAI,CAAC,EAAE,KAAK,GAAG,EAAE,IAAI,IAAI;IACnE,MAAM,UAAU,SAAS;IACzB,MAAM,SAAS,MAAM,IAAI,CAAC,IAAI,IAAI;IAClC,MAAM,SAAS,IAAI;IACnB,KAAK,MAAM,QAAQ,OAAQ;QACzB,MAAM,KAAK,MAAM,EAAE,CAAC,GAAG,CAAC,SAAS;QACjC,IAAI,OAAO,KAAK,MAAM,CAAC,KAAK,GAAG;QAC/B,MAAM,MAAM,KAAK,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC,GAAG,KAAK,GAAG,IAAI,CAAC,KAAK,GAAG;QACzD,MAAM,WAAW,MAAM,GAAG,CAAC,GAAG,CAAC;QAC/B,UAAU,QAAQ,CAAC,IAAI;YACrB,MAAM,IAAI,MAAM,IAAI,CAAC,GAAG,CAAC;YACzB,MAAM,QAAQ,KAAK,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,EAAE,MAAM,GAAG,CAAC,MAAM,KAAK,IAAI,CAAC,CAAC,CAAC;YACpE,MAAM,WAAW,MAAM,CAAC,AAAC,KAAK,CAAC,KAAK,CAAC,IAAK,CAAC,SAAS,CAAC,CAAC;YACtD,OAAO,GAAG,CAAC,OAAO,CAAC,OAAO,GAAG,CAAC,UAAU,CAAC,IAAI;QAC/C;IACF;IACA,MAAM,SAAS,MAAM,IAAI,CAAC,OAAO,OAAO,IACrC,IAAI,CAAC,CAAC,GAAG,KAAO,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC,EAAE,EAC5B,KAAK,CAAC,GAAG,GACT,GAAG,CAAC,CAAC,CAAC,OAAO,EAAE;QACd,MAAM,IAAI,MAAM,IAAI,CAAC,GAAG,CAAC;QACzB,OAAO;YAAE,IAAI,EAAE,EAAE;YAAE,KAAK,EAAE,GAAG;YAAE,OAAO,EAAE,KAAK;YAAE,MAAM,EAAE,IAAI;YAAE,OAAO;QAAE;IACxE;IACF,OAAO;AACT","debugId":null}},
    {"offset": {"line": 176, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/NChinnappan/SourceAI/UI/shell-app/src/app/api/rag/status/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport { size, listDocs } from '@/lib/rag/store';\n\nexport const runtime = 'nodejs';\n\nexport async function GET(_req: NextRequest) {\n  try {\n    const sz = size();\n    const sample = listDocs(50);\n    return NextResponse.json({ ok: true, size: sz, sample });\n  } catch (e: unknown) {\n    const msg = e instanceof Error ? e.message : String(e);\n    return NextResponse.json({ error: msg }, { status: 500 });\n  }\n}\n\n"],"names":[],"mappings":";;;;;;AAAA;AACA;;;AAEO,MAAM,UAAU;AAEhB,eAAe,IAAI,IAAiB;IACzC,IAAI;QACF,MAAM,KAAK,IAAA,oIAAI;QACf,MAAM,SAAS,IAAA,wIAAQ,EAAC;QACxB,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,IAAI;YAAM,MAAM;YAAI;QAAO;IACxD,EAAE,OAAO,GAAY;QACnB,MAAM,MAAM,aAAa,QAAQ,EAAE,OAAO,GAAG,OAAO;QACpD,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAI,GAAG;YAAE,QAAQ;QAAI;IACzD;AACF","debugId":null}}]
}